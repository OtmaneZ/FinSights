"""
TRESORIS V3 - Orchestrator Brain
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

Le cerveau central qui:
1. D√©cide QUELS engines utiliser
2. Combine les r√©sultats intelligemment
3. G√©n√®re des insights narratifs
4. Apprend des interactions

C'est le "ChatGPT" de Tresoris - l'interface intelligente au-dessus des engines.
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
import pandas as pd
import json

# LLM Layer
from llm.claude import LLMLayer, LLMResponse

# Identity & Personality
from agent.identity import (
    get_system_prompt,
    get_identity,
    get_personality,
    SYSTEM_PROMPTS,
    PRIORITIZATION_RULES,
    SIGNATURE_PHRASES,
    RESPONSE_TEMPLATES
)


class AnalysisMode(str, Enum):
    """Mode d'analyse demand√©"""
    QUICK_CHECK = "quick_check"              # Check rapide routine
    DEEP_DIVE = "deep_dive"                  # Analyse approfondie
    SCENARIO_PLANNING = "scenario_planning"  # Planification sc√©narios
    DECISION_SUPPORT = "decision_support"    # Support d√©cision
    VARIANCE_ANALYSIS = "variance_analysis"  # Analyse √©carts
    STRESS_TEST = "stress_test"              # Test de stress
    MARGIN_ANALYSIS = "margin_analysis"      # Analyse marges
    COST_ANALYSIS = "cost_analysis"          # Analyse co√ªts


@dataclass
class OrchestratorContext:
    """Contexte pour l'orchestrateur"""
    mode: AnalysisMode
    question: Optional[str]                  # Question du DAF
    focus_area: Optional[str]                # Zone de focus (client, produit, etc)
    time_horizon: str = "4_weeks"            # Horizon temporel
    risk_appetite: str = "moderate"          # App√©tit risque
    
    # Donn√©es disponibles
    has_invoices: bool = False
    has_costs: bool = False
    has_budget: bool = False
    has_payments: bool = False
    
    # Pr√©f√©rences utilisateur
    detail_level: str = "executive"          # "executive" | "detailed" | "deep"
    output_format: str = "narrative"         # "narrative" | "bullet_points" | "table"


@dataclass
class OrchestratedInsight:
    """Insight orchestr√© combinant plusieurs engines"""
    timestamp: datetime
    mode: AnalysisMode
    question: str
    
    # R√©sultats engines utilis√©s
    engines_used: List[str]
    raw_results: Dict[str, Any]
    
    # Synth√®se intelligente
    executive_summary: str                   # 2-3 phrases pour CEO
    key_findings: List[str]                  # 3-5 findings principaux
    narrative: str                           # Histoire compl√®te g√©n√©r√©e par LLM
    
    # Actions recommand√©es
    immediate_actions: List[Dict]            # √Ä faire maintenant
    watchlist: List[Dict]                    # √Ä surveiller
    
    # M√©ta
    confidence_score: float                  # 0-100
    data_quality: str                        # "excellent" | "good" | "limited"
    
    def to_dict(self) -> Dict:
        return {
            "timestamp": self.timestamp.isoformat(),
            "mode": self.mode.value,
            "question": self.question,
            "engines_used": self.engines_used,
            "executive_summary": self.executive_summary,
            "key_findings": self.key_findings,
            "narrative": self.narrative,
            "immediate_actions": self.immediate_actions,
            "watchlist": self.watchlist,
            "confidence_score": self.confidence_score,
            "data_quality": self.data_quality
        }


class TresorisOrchestrator:
    """
    Le cerveau de TRESORIS.
    
    Orchestration intelligente:
    - D√©cide quels engines appeler selon le contexte
    - Combine les r√©sultats de mani√®re coh√©rente
    - G√©n√®re des insights narratifs via LLM
    - Apprend des interactions pass√©es
    
    Identit√©: Charg√©e depuis agent/identity.py
    """
    
    # IDENTITY charg√©e depuis identity.py
    IDENTITY = get_identity()
    PERSONALITY = get_personality()

    def __init__(self, agent):
        """
        Args:
            agent: Instance de RiskRequalificationAgent avec tous les engines
        """
        self.agent = agent
        self.llm = LLMLayer()
        self.identity = get_identity()
        self.personality = get_personality()
        
        # Historique des analyses pour apprentissage
        self.analysis_history: List[Dict] = []
        
        print("üß† TRESORIS Orchestrator initialis√©")
        print(f"   Identit√©: {self.personality['name']} - {self.personality['role']}")
        print("   13 engines disponibles")
        print("   LLM: Claude 3.5 Sonnet via OpenRouter")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ORCHESTRATION PRINCIPALE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    async def analyze(
        self,
        question: str,
        context: OrchestratorContext,
        data: Dict[str, pd.DataFrame]
    ) -> OrchestratedInsight:
        """
        Point d'entr√©e principal : analyse orchestr√©e.
        
        Workflow:
        1. Comprendre la question
        2. S√©lectionner les engines pertinents
        3. Ex√©cuter les analyses
        4. Combiner les r√©sultats
        5. G√©n√©rer narrative LLM
        6. Recommandations actionnables
        
        Args:
            question: Question du DAF ("Pourquoi ma marge baisse?")
            context: Contexte d'analyse
            data: DataFrames disponibles
        """
        
        print(f"\nüß† Analyse orchestr√©e: {question}")
        print(f"   Mode: {context.mode.value}")
        
        # 1. S√©lectionner engines
        engines_to_use = self._select_engines(context)
        print(f"   Engines s√©lectionn√©s: {', '.join(engines_to_use)}")
        
        # 2. Ex√©cuter analyses
        raw_results = await self._execute_engines(engines_to_use, data, context)
        
        # 3. Extraire key findings
        key_findings = self._extract_key_findings(raw_results, engines_to_use)
        
        # 4. G√©n√©rer executive summary
        exec_summary = self._generate_executive_summary(key_findings, raw_results)
        
        # 5. G√©n√©rer narrative compl√®te via LLM
        narrative = await self._generate_narrative(
            question=question,
            findings=key_findings,
            raw_results=raw_results,
            context=context
        )
        
        # 6. Actions recommand√©es
        immediate, watchlist = self._extract_actions(raw_results, engines_to_use)
        
        # 7. √âvaluer confiance et qualit√©
        confidence = self._calculate_confidence(raw_results, data)
        quality = self._assess_data_quality(data)
        
        # Cr√©er insight
        insight = OrchestratedInsight(
            timestamp=datetime.now(),
            mode=context.mode,
            question=question,
            engines_used=engines_to_use,
            raw_results=raw_results,
            executive_summary=exec_summary,
            key_findings=key_findings,
            narrative=narrative,
            immediate_actions=immediate,
            watchlist=watchlist,
            confidence_score=confidence,
            data_quality=quality
        )
        
        # Stocker pour apprentissage
        self._store_analysis(insight)
        
        return insight
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # S√âLECTION INTELLIGENTE DES ENGINES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _select_engines(self, context: OrchestratorContext) -> List[str]:
        """S√©lectionne intelligemment les engines selon le mode"""
        
        engines = []
        
        if context.mode == AnalysisMode.QUICK_CHECK:
            # Check routine rapide
            engines = ["payment_patterns", "early_warning", "smart_forecast"]
        
        elif context.mode == AnalysisMode.DEEP_DIVE:
            # Analyse compl√®te
            engines = [
                "payment_patterns",
                "early_warning",
                "client_scoring",
                "smart_forecast",
                "margin_analyzer",      # V3
                "causal_analyzer"       # V3
            ]
        
        elif context.mode == AnalysisMode.MARGIN_ANALYSIS:
            # Focus marges
            engines = [
                "margin_analyzer",      # V3
                "causal_analyzer",      # V3
                "variance_analyzer"     # V3 (si budget disponible)
            ]
        
        elif context.mode == AnalysisMode.COST_ANALYSIS:
            # Focus co√ªts
            engines = [
                "cost_drift_analyzer",  # V3
                "variance_analyzer",    # V3
                "causal_analyzer"       # V3
            ]
        
        elif context.mode == AnalysisMode.STRESS_TEST:
            # Stress testing
            engines = [
                "stress_tester",        # V3
                "smart_forecast",
                "early_warning"
            ]
        
        elif context.mode == AnalysisMode.DECISION_SUPPORT:
            # Aide √† la d√©cision
            engines = [
                "decision_arbiter",     # V3
                "stress_tester",        # V3
                "smart_forecast"
            ]
        
        elif context.mode == AnalysisMode.VARIANCE_ANALYSIS:
            # Analyse √©carts
            engines = [
                "variance_analyzer",    # V3
                "causal_analyzer",      # V3
                "cost_drift_analyzer"   # V3
            ]
        
        elif context.mode == AnalysisMode.SCENARIO_PLANNING:
            # Planification sc√©narios
            engines = [
                "smart_forecast",
                "stress_tester",        # V3
                "seasonality"
            ]
        
        # Filtrer selon donn√©es disponibles
        if not context.has_costs:
            engines = [e for e in engines if e not in ["cost_drift_analyzer", "margin_analyzer"]]
        
        if not context.has_budget:
            engines = [e for e in engines if e != "variance_analyzer"]
        
        return engines
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # EX√âCUTION DES ENGINES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    async def _execute_engines(
        self,
        engines: List[str],
        data: Dict[str, pd.DataFrame],
        context: OrchestratorContext
    ) -> Dict[str, Any]:
        """Ex√©cute les engines s√©lectionn√©s"""
        
        results = {}
        
        for engine_name in engines:
            try:
                if engine_name == "margin_analyzer" and "invoices" in data:
                    result = self.agent.margin_analyzer.analyze_client_margin(
                        invoices=data["invoices"],
                        costs=data.get("costs"),
                        payments=data.get("payments")
                    )
                    results["margin"] = result.to_dict() if hasattr(result, 'to_dict') else result
                
                elif engine_name == "cost_drift_analyzer" and "costs" in data:
                    result = self.agent.cost_drift_analyzer.analyze_drift(
                        cost_history=data["costs"]
                    )
                    results["cost_drift"] = result.to_dict() if hasattr(result, 'to_dict') else result
                
                elif engine_name == "causal_analyzer":
                    # Analyse causale n√©cessite effet + donn√©es
                    result = self.agent.causal_analyzer.analyze(
                        effect="Variation observ√©e",
                        data=data
                    )
                    results["causal"] = result.to_dict() if hasattr(result, 'to_dict') else result
                
                elif engine_name == "variance_analyzer" and "budget" in data:
                    result = self.agent.variance_analyzer.analyze_variances(
                        actual_data=data["actual"],
                        budget_data=data["budget"]
                    )
                    results["variance"] = result.to_dict() if hasattr(result, 'to_dict') else result
                
                elif engine_name == "stress_tester":
                    # Stress test n√©cessite donn√©es tr√©so
                    result = self.agent.stress_tester.run_full_stress_test(
                        current_cash=data.get("current_cash", 100000),
                        monthly_revenues=data.get("monthly_revenues", 50000),
                        monthly_costs=data.get("monthly_costs", 40000)
                    )
                    results["stress"] = result.to_dict() if hasattr(result, 'to_dict') else result
                
                # Engines V2
                elif engine_name == "payment_patterns" and "invoices" in data:
                    # Patterns de paiement
                    results["patterns"] = "TODO: Implement payment patterns call"
                
                elif engine_name == "smart_forecast":
                    results["forecast"] = "TODO: Implement smart forecast call"
                
                elif engine_name == "early_warning":
                    results["warnings"] = "TODO: Implement early warning call"
                
                print(f"     ‚úÖ {engine_name}")
                
            except Exception as e:
                print(f"     ‚ùå {engine_name}: {e}")
                results[engine_name] = {"error": str(e)}
        
        return results
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # EXTRACTION & SYNTH√àSE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _extract_key_findings(
        self,
        raw_results: Dict[str, Any],
        engines_used: List[str]
    ) -> List[str]:
        """Extrait les findings cl√©s de chaque engine"""
        
        findings = []
        
        # Margin analysis
        if "margin" in raw_results:
            m = raw_results["margin"]
            if isinstance(m, dict):
                findings.append(f"Marge nette globale: {m.get('net_margin_pct', 0):.1f}%")
                if m.get('anomalies'):
                    findings.append(f"{len(m['anomalies'])} anomalies de marge d√©tect√©es")
        
        # Cost drift
        if "cost_drift" in raw_results:
            cd = raw_results["cost_drift"]
            if isinstance(cd, dict):
                findings.append(f"Inflation interne: {cd.get('internal_inflation', 0)*100:.1f}%")
                if cd.get('ghost_costs'):
                    findings.append(f"{len(cd['ghost_costs'])} co√ªts fant√¥mes d√©tect√©s")
        
        # Variance
        if "variance" in raw_results:
            v = raw_results["variance"]
            if isinstance(v, dict):
                findings.append(f"√âcart budget: {v.get('result_variance_pct', 0)*100:.1f}%")
        
        # Stress test
        if "stress" in raw_results:
            s = raw_results["stress"]
            if isinstance(s, dict) and "monte_carlo" in s:
                mc = s["monte_carlo"]
                findings.append(f"Probabilit√© cash n√©gatif: {mc.get('prob_negative_cash', 0)*100:.1f}%")
        
        # Causal
        if "causal" in raw_results:
            c = raw_results["causal"]
            if isinstance(c, dict) and "chains" in c:
                findings.append(f"{len(c['chains'])} cha√Ænes causales identifi√©es")
        
        return findings[:5]  # Top 5
    
    def _generate_executive_summary(
        self,
        findings: List[str],
        raw_results: Dict
    ) -> str:
        """G√©n√®re executive summary (2-3 phrases)"""
        
        if not findings:
            return "Analyse en cours, donn√©es insuffisantes pour synth√®se."
        
        # Synth√®se basique (sera enrichie par LLM)
        summary = f"{len(findings)} insights cl√©s d√©tect√©s. "
        
        # Ajouter contexte risque
        if "stress" in raw_results:
            s = raw_results["stress"]
            if isinstance(s, dict):
                risk_level = s.get("overall_risk_level", "moderate")
                summary += f"Niveau de risque: {risk_level}. "
        
        summary += "Actions recommand√©es disponibles ci-dessous."
        
        return summary
    
    def _get_prompt_for_mode(self, mode: AnalysisMode) -> str:
        """Retourne le system prompt adapt√© au mode d'analyse"""
        
        mode_to_prompt = {
            AnalysisMode.QUICK_CHECK: "quick_check",
            AnalysisMode.DEEP_DIVE: "deep_dive",
            AnalysisMode.SCENARIO_PLANNING: "stress_test",
            AnalysisMode.DECISION_SUPPORT: "decision_support",
            AnalysisMode.VARIANCE_ANALYSIS: "causal_explanation",
            AnalysisMode.STRESS_TEST: "stress_test",
            AnalysisMode.MARGIN_ANALYSIS: "deep_dive",
            AnalysisMode.COST_ANALYSIS: "causal_explanation",
        }
        
        prompt_key = mode_to_prompt.get(mode, "orchestrator")
        return get_system_prompt(prompt_key)
    
    async def _generate_narrative(
        self,
        question: str,
        findings: List[str],
        raw_results: Dict,
        context: OrchestratorContext
    ) -> str:
        """G√©n√®re narrative compl√®te via LLM avec identit√© TRESORIS"""
        
        # R√©cup√©rer le system prompt adapt√© au mode
        base_prompt = self._get_prompt_for_mode(context.mode)
        
        # Enrichir avec contexte sp√©cifique
        system_prompt = f"""{base_prompt}

---
CONTEXTE DE L'ANALYSE:
- Mode: {context.mode.value}
- Engines utilis√©s: {len(raw_results)}
- Horizon: {context.time_horizon}
- Niveau de d√©tail: {context.detail_level}

Question du DAF: "{question}"
"""

        # Pr√©parer les r√©sultats pour le LLM
        results_summary = self._format_results_for_llm(raw_results, findings)
        
        user_prompt = f"""J'ai besoin de ton analyse compl√®te.

## FINDINGS CL√âS:
{chr(10).join([f"‚Ä¢ {f}" for f in findings])}

## R√âSULTATS D√âTAILL√âS DES ENGINES:
{results_summary}

---

R√©dige une r√©ponse compl√®te qui:
1. R√©pond directement √† la question "{question}"
2. Synth√©tise les findings de mani√®re narrative
3. Explique les CAUSES (pas juste les sympt√¥mes)
4. Propose 2-3 actions concr√®tes et prioris√©es
5. Termine par une phrase de suivi

N'oublie pas: tu es TRESORIS, le DAF augment√©. Sois pr√©cis, factuel, orient√© action."""

        try:
            response = await self.llm._call_llm([
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ], max_tokens=1500)
            
            return response.content if response.success else self._fallback_narrative(findings)
        
        except Exception as e:
            print(f"‚ö†Ô∏è LLM error: {e}")
            return self._fallback_narrative(findings)
    
    def _format_results_for_llm(self, raw_results: Dict, findings: List[str]) -> str:
        """Formate les r√©sultats pour le LLM"""
        
        formatted = []
        
        for engine, result in raw_results.items():
            if isinstance(result, dict) and "error" not in result:
                formatted.append(f"\n{engine.upper()}:")
                # Extraire 3-5 points cl√©s
                formatted.append(json.dumps(result, indent=2, ensure_ascii=False)[:500])
        
        return "\n".join(formatted)
    
    def _fallback_narrative(self, findings: List[str]) -> str:
        """Narrative de fallback si LLM indisponible"""
        
        narrative = "# Analyse Tresoris\n\n"
        narrative += "## Synth√®se\n\n"
        narrative += "\n".join([f"- {f}" for f in findings])
        narrative += "\n\n## Recommandations\n\n"
        narrative += "Actions d√©taill√©es disponibles ci-dessous."
        
        return narrative
    
    def _extract_actions(
        self,
        raw_results: Dict,
        engines_used: List[str]
    ) -> Tuple[List[Dict], List[Dict]]:
        """Extrait actions imm√©diates et watchlist"""
        
        immediate = []
        watchlist = []
        
        # Extraction basique (√† enrichir)
        if "variance" in raw_results:
            v = raw_results["variance"]
            if isinstance(v, dict) and "corrective_actions" in v:
                immediate.extend(v["corrective_actions"][:3])
        
        if "stress" in raw_results:
            s = raw_results["stress"]
            if isinstance(s, dict) and "hedging_actions" in s:
                immediate.extend(s["hedging_actions"][:2])
        
        return immediate, watchlist
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # QUALIT√â & CONFIANCE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _calculate_confidence(self, raw_results: Dict, data: Dict) -> float:
        """Calcule score de confiance 0-100"""
        
        score = 50  # Base
        
        # +10 par engine r√©ussi
        successful = sum(1 for r in raw_results.values() if "error" not in str(r))
        score += successful * 10
        
        # +20 si donn√©es riches
        if len(data) >= 3:
            score += 20
        
        return min(100, score)
    
    def _assess_data_quality(self, data: Dict) -> str:
        """√âvalue qualit√© des donn√©es"""
        
        if len(data) >= 4:
            return "excellent"
        elif len(data) >= 2:
            return "good"
        else:
            return "limited"
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # APPRENTISSAGE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _store_analysis(self, insight: OrchestratedInsight):
        """Stocke l'analyse pour apprentissage futur"""
        
        self.analysis_history.append({
            "timestamp": insight.timestamp.isoformat(),
            "mode": insight.mode.value,
            "question": insight.question,
            "engines_used": insight.engines_used,
            "confidence": insight.confidence_score
        })
        
        # Garder seulement les 100 derni√®res
        if len(self.analysis_history) > 100:
            self.analysis_history = self.analysis_history[-100:]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# TESTS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def _test_orchestrator():
    """Test de l'orchestrateur"""
    
    print("\n" + "="*70)
    print("TRESORIS ORCHESTRATOR - TEST")
    print("="*70)
    
    # Mock agent avec engines
    class MockAgent:
        def __init__(self):
            from engine.margin_analyzer import MarginAnalyzer
            from engine.cost_drift_analyzer import CostDriftAnalyzer
            from engine.causal_analyzer import CausalAnalyzer
            from engine.variance_analyzer import VarianceAnalyzer
            from engine.stress_tester import StressTester
            from engine.decision_arbiter import DecisionArbiter
            
            self.margin_analyzer = MarginAnalyzer()
            self.cost_drift_analyzer = CostDriftAnalyzer()
            self.causal_analyzer = CausalAnalyzer()
            self.variance_analyzer = VarianceAnalyzer()
            self.stress_tester = StressTester()
            self.decision_arbiter = DecisionArbiter()
    
    agent = MockAgent()
    orchestrator = TresorisOrchestrator(agent)
    
    # Test context
    context = OrchestratorContext(
        mode=AnalysisMode.STRESS_TEST,
        question="Quel est le risque de cash n√©gatif dans les 6 prochains mois?",
        focus_area="tr√©sorerie",
        has_invoices=True,
        has_costs=True
    )
    
    # Mock data
    data = {
        "current_cash": 150000,
        "monthly_revenues": 80000,
        "monthly_costs": 65000
    }
    
    # Ex√©cuter
    result = await orchestrator.analyze(
        question=context.question,
        context=context,
        data=data
    )
    
    print(f"\nüìä R√âSULTAT:")
    print(f"   Engines utilis√©s: {', '.join(result.engines_used)}")
    print(f"   Confiance: {result.confidence_score:.0f}%")
    print(f"   Qualit√© donn√©es: {result.data_quality}")
    
    print(f"\nüí° EXECUTIVE SUMMARY:")
    print(f"   {result.executive_summary}")
    
    print(f"\nüìã KEY FINDINGS:")
    for f in result.key_findings:
        print(f"   ‚Ä¢ {f}")
    
    print(f"\nüìù NARRATIVE (extrait):")
    print(result.narrative[:300] + "...")
    
    return result


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# M√âTHODES QUICK ACCESS (Raccourcis pour le chat/API)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class TresorisQuickMethods:
    """
    M√©thodes rapides pour acc√®s depuis l'API ou le chat.
    Encapsule les appels fr√©quents avec des contextes pr√©-configur√©s.
    """
    
    def __init__(self, orchestrator: TresorisOrchestrator):
        self.orchestrator = orchestrator
    
    async def morning_check(self, data: Dict) -> OrchestratedInsight:
        """
        Check rapide du matin - 30 secondes de lecture.
        
        Usage: Routine quotidienne du DAF au caf√©.
        """
        context = OrchestratorContext(
            mode=AnalysisMode.QUICK_CHECK,
            question="Quelle est ma situation cash ce matin ?",
            detail_level="executive",
            output_format="bullet_points",
            has_invoices=True,
            has_payments=True
        )
        
        return await self.orchestrator.analyze(
            question=context.question,
            context=context,
            data=data
        )
    
    async def explain_variance(self, metric: str, data: Dict) -> OrchestratedInsight:
        """
        Explique pourquoi une m√©trique a chang√©.
        
        Usage: "Pourquoi ma marge a baiss√© de 3 points ?"
        """
        context = OrchestratorContext(
            mode=AnalysisMode.VARIANCE_ANALYSIS,
            question=f"Pourquoi {metric} a chang√© ?",
            focus_area=metric,
            detail_level="detailed",
            has_invoices=True,
            has_costs=True,
            has_budget=True
        )
        
        return await self.orchestrator.analyze(
            question=context.question,
            context=context,
            data=data
        )
    
    async def stress_test_scenario(self, scenario: str, data: Dict) -> OrchestratedInsight:
        """
        Test de stress sur un sc√©nario sp√©cifique.
        
        Usage: "Que se passe-t-il si je perds 2 gros clients ?"
        """
        context = OrchestratorContext(
            mode=AnalysisMode.STRESS_TEST,
            question=f"Simulation: {scenario}",
            focus_area="tr√©sorerie",
            time_horizon="6_months",
            detail_level="detailed"
        )
        
        return await self.orchestrator.analyze(
            question=context.question,
            context=context,
            data=data
        )
    
    async def decision_compare(self, option_a: str, option_b: str, data: Dict) -> OrchestratedInsight:
        """
        Compare deux options de d√©cision.
        
        Usage: "Recruter un CDI vs freelance pour ce poste ?"
        """
        context = OrchestratorContext(
            mode=AnalysisMode.DECISION_SUPPORT,
            question=f"Comparer: {option_a} vs {option_b}",
            detail_level="detailed",
            output_format="table"
        )
        
        return await self.orchestrator.analyze(
            question=context.question,
            context=context,
            data=data
        )
    
    async def generate_dg_note(self, data: Dict) -> str:
        """
        G√©n√®re une note pour la Direction G√©n√©rale.
        
        Usage: Pr√©parer un point tr√©sorerie pour le COMEX.
        """
        context = OrchestratorContext(
            mode=AnalysisMode.DEEP_DIVE,
            question="G√©n√©rer une note tr√©sorerie pour la DG",
            detail_level="executive",
            output_format="narrative"
        )
        
        insight = await self.orchestrator.analyze(
            question=context.question,
            context=context,
            data=data
        )
        
        # Formater en note DG
        from datetime import datetime
        note = f"""# Point Tr√©sorerie - {datetime.now().strftime('%B %Y')}

{insight.executive_summary}

## Synth√®se
{insight.narrative}

## Actions en cours
"""
        for action in insight.immediate_actions[:3]:
            if isinstance(action, dict):
                note += f"- {action.get('action', action.get('description', str(action)))}\n"
            else:
                note += f"- {action}\n"
        
        note += "\n---\n*Note g√©n√©r√©e par TRESORIS*"
        
        return note


if __name__ == "__main__":
    import asyncio
    asyncio.run(_test_orchestrator())
